{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import calendar\n",
    "from dash.dependencies import Input, Output\n",
    "from datetime import datetime\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the working directory for fahrzeiten\n",
    "fahrzeiten_dir = '../raw_data/fahrzeiten_2022/'\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "os.makedirs(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "fahrzeiten_filenames = [filename for filename in os.listdir(fahrzeiten_dir) if filename.endswith('.csv') and filename.startswith('Fahrzeiten_SOLL_IST')]\n",
    "fahrzeiten_head = pd.read_csv(fahrzeiten_dir + fahrzeiten_filenames[0], nrows=0).columns\n",
    "\n",
    "# Define the data types for each column\n",
    "dtypes = {\n",
    "    'linie': 'int16',\n",
    "    'richtung': 'int8',\n",
    "    'betriebsdatum': 'object',\n",
    "    'fahrzeug': 'int32',\n",
    "    'kurs': 'int16',\n",
    "    'seq_von': 'int32',\n",
    "    'halt_diva_von': 'int32',\n",
    "    'halt_punkt_diva_von': 'int32',\n",
    "    'halt_kurz_von1': 'object',\n",
    "    'datum_von': 'object',\n",
    "    'soll_an_von': 'int32',\n",
    "    'ist_an_von': 'int32',\n",
    "    'soll_ab_von': 'int32',\n",
    "    'ist_ab_von': 'int32',\n",
    "    'seq_nach': 'int32',\n",
    "    'halt_diva_nach': 'int32',\n",
    "    'halt_punkt_diva_nach': 'int32',\n",
    "    'halt_kurz_nach1': 'object',\n",
    "    'datum_nach': 'object',\n",
    "    'soll_an_nach': 'int32',\n",
    "    'ist_an_nach1': 'int32',\n",
    "    'soll_ab_nach': 'int32',\n",
    "    'ist_ab_nach': 'int32',\n",
    "    'fahrt_id': 'int64',\n",
    "    'fahrweg_id': 'int64',\n",
    "    'fw_no': 'int16',\n",
    "    'fw_typ': 'int8',\n",
    "    'fw_kurz': 'object',\n",
    "    'fw_lang': 'object',\n",
    "    'umlauf_von': 'int64',\n",
    "    'halt_id_von': 'int64',\n",
    "    'halt_id_nach': 'int64',\n",
    "    'halt_punkt_id_von': 'int64',\n",
    "    'halt_punkt_id_nach': 'int64'\n",
    "}\n",
    "\n",
    "def get_fahrzeiten_dask_df(filename, columns=None):\n",
    "    if columns is None:\n",
    "        columns = fahrzeiten_head\n",
    "    df = dd.read_csv(fahrzeiten_dir + filename, usecols=columns, dtype=dtypes)\n",
    "    return df.compute()\n",
    "\n",
    "fahrzeiten_dfs = {filename: get_fahrzeiten_dask_df(filename) for filename in fahrzeiten_filenames}\n",
    "\n",
    "# Function to get the data from the csv files and return a dataframe\n",
    "def csv_to_df(filepath):\n",
    "    try:\n",
    "        return pd.read_csv(filepath, sep=',')\n",
    "    except pd.errors.ParserError:\n",
    "        return pd.read_csv(filepath, sep=';')\n",
    "\n",
    "passagierfrequenz_df = csv_to_df('../raw_data/passagierfrequenz.csv')\n",
    "haltestelle_df = csv_to_df(fahrzeiten_dir + 'haltestelle.csv')\n",
    "haltepunkt_df = csv_to_df(fahrzeiten_dir + 'haltepunkt.csv')\n",
    "\n",
    "dataframes = {\n",
    "    'passagierfrequenz': passagierfrequenz_df,\n",
    "    f'haltestelle ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})': haltestelle_df,\n",
    "    f'haltepunkt ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})': haltepunkt_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fahrzeiten CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function displays a UI for exploring CSV files in the '../raw_data/fahrzeiten' directory.\n",
    "It provides a dropdown to select a file, and 'Head', 'Previous', 'Next', and 'Tail' buttons to navigate through the data.\n",
    "The data is displayed in a DataFrame format, showing 10 rows at a time.\n",
    "\"\"\"\n",
    "def show_all_fahrzeiten_csvs():\n",
    "    start = 0\n",
    "    df = None\n",
    "\n",
    "    # Create UI elements\n",
    "    head_button = widgets.Button(description='Head')\n",
    "    prev_button = widgets.Button(description='Previous')\n",
    "    next_button = widgets.Button(description='Next')\n",
    "    tail_button = widgets.Button(description='Tail')\n",
    "    output = widgets.Output()\n",
    "    column_dropdown = widgets.Dropdown(options=df.columns if df is not None else [])\n",
    "    search_input = widgets.Text(value='', placeholder='Type something', description='Search:', disabled=False)\n",
    "    search_button = widgets.Button(description='Search')\n",
    "    dimensions_label = widgets.HTML()\n",
    "    not_checkbox = widgets.Checkbox(value=False, description='NOT', layout=widgets.Layout(width='auto'))\n",
    "    describe_button = widgets.Button(description='Describe')\n",
    "    \n",
    "    # Function to load CSV file into DataFrame\n",
    "    def show_csv(button_instance=None):\n",
    "        nonlocal start, df\n",
    "        start = 0\n",
    "        df = fahrzeiten_dfs[filenames[dropdown.value]]\n",
    "        column_dropdown.options = df.columns\n",
    "        show_output()\n",
    "\n",
    "    # Event handlers for button clicks\n",
    "    def on_head_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = 0\n",
    "        show_output()\n",
    "\n",
    "    def on_prev_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = max(0, start-10)\n",
    "        show_output()\n",
    "\n",
    "    def on_next_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = min(len(df)-10, start+10)\n",
    "        show_output()\n",
    "\n",
    "    def on_tail_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = len(df)-10\n",
    "        show_output()\n",
    "\n",
    "    # Function to display DataFrame in output widget\n",
    "    def show_output():\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            display(HTML('<div style=\"overflow-x: auto; white-space: nowrap;\">' \n",
    "                        + df.iloc[start:start+10].to_html() + '</div>'))\n",
    "            # Update the dimensions label\n",
    "            dimensions_label.value = f'<h4>Dimensions: {df.shape}</h4>'\n",
    "    \n",
    "    # Function to show search results\n",
    "    def show_search(button_instance=None):\n",
    "        nonlocal df\n",
    "        if search_input.value:\n",
    "            if not_checkbox.value:\n",
    "                df = df[~df[column_dropdown.value].astype(str).str.contains(search_input.value)]\n",
    "            else:\n",
    "                df = df[df[column_dropdown.value].astype(str).str.contains(search_input.value)]\n",
    "        show_output()\n",
    "    \n",
    "    # Function to show description\n",
    "    def show_description(button_instance=None):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if df is not None:\n",
    "                desc_df = df.describe()\n",
    "                desc_df = desc_df.applymap(lambda x: '{:.0f}'.format(x) if x == int(x) else '{:.4f}'.format(x))\n",
    "                display(HTML('<div style=\"overflow-x: auto; white-space: nowrap;\">' \n",
    "                        + desc_df.to_html() + '</div>'))\n",
    "            else:\n",
    "                display(HTML('<p style=\"color: red;\">Please first select \"Show\".</p>'))\n",
    "\n",
    "    # Get list of CSV files\n",
    "    filenames = {f'{filename[26:28]}.{filename[24:26]}.{filename[20:24]} bis {filename[35:37]}.{filename[33:35]}.{filename[29:33]}': filename for filename in fahrzeiten_filenames}\n",
    "    \n",
    "    # Create dropdown and show button\n",
    "    dropdown = widgets.Dropdown(options=list(filenames.keys()))\n",
    "    show_button = widgets.Button(description='Show')\n",
    "\n",
    "    # Display UI elements\n",
    "    title = widgets.HTML('<h2 style=\"text-align: center;\">Fahrzeiten: SOLL und IST</h2>')\n",
    "    box_layout = widgets.Layout(display='flex', justify_content='center')\n",
    "    display(\n",
    "        widgets.VBox(\n",
    "            [\n",
    "                title, widgets.HBox([dropdown, show_button, describe_button], layout=box_layout),\n",
    "                widgets.HBox([not_checkbox, column_dropdown, search_input, search_button], layout=box_layout),\n",
    "                output,\n",
    "                widgets.HBox([dimensions_label], layout=widgets.Layout(justify_content='flex-start')),\n",
    "                widgets.HBox([head_button, prev_button, next_button, tail_button], layout=box_layout)\n",
    "            ],\n",
    "            layout=box_layout\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Attach event handlers to buttons\n",
    "    show_button.on_click(show_csv)\n",
    "    describe_button.on_click(show_description)\n",
    "    head_button.on_click(on_head_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    tail_button.on_click(on_tail_button_clicked)\n",
    "    search_button.on_click(show_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_all_fahrzeiten_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function provides a user interface for exploring CSV files in the '../raw_data' directory.\n",
    "The user can navigate through the data using 'Head', 'Previous', 'Next', and 'Tail' buttons, which display the data in chunks of 10 rows at a time.\n",
    "\"\"\"\n",
    "def show_other_csvs():\n",
    "    start = 0\n",
    "    df = None\n",
    "\n",
    "    # Create UI elements\n",
    "    head_button = widgets.Button(description='Head')\n",
    "    prev_button = widgets.Button(description='Previous')\n",
    "    next_button = widgets.Button(description='Next')\n",
    "    tail_button = widgets.Button(description='Tail')\n",
    "    output = widgets.Output()\n",
    "    column_dropdown = widgets.Dropdown(options=df.columns if df is not None else [])\n",
    "    search_input = widgets.Text(value='', placeholder='Type something', description='Search:', disabled=False)\n",
    "    search_button = widgets.Button(description='Search')\n",
    "    dimensions_label = widgets.HTML()\n",
    "    not_checkbox = widgets.Checkbox(value=False, description='NOT', layout=widgets.Layout(width='auto'))\n",
    "    describe_button = widgets.Button(description='Describe')\n",
    "\n",
    "    # Function to load DataFrame from the list\n",
    "    def show_df(button_instance=None):\n",
    "        nonlocal start, df\n",
    "        start = 0\n",
    "        df = dataframes[dropdown.value]\n",
    "        column_dropdown.options = df.columns\n",
    "        show_output()\n",
    "\n",
    "    # Event handlers for button clicks\n",
    "    def on_head_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = 0\n",
    "        show_output()\n",
    "\n",
    "    def on_prev_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = max(0, start-10)\n",
    "        show_output()\n",
    "\n",
    "    def on_next_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = min(len(df)-10, start+10)\n",
    "        show_output()\n",
    "\n",
    "    def on_tail_button_clicked(b):\n",
    "        nonlocal start\n",
    "        start = len(df)-10\n",
    "        show_output()\n",
    "\n",
    "    # Function to display DataFrame in output widget\n",
    "    def show_output():\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            display(HTML('<div style=\"overflow-x: auto; white-space: nowrap;\">' \n",
    "                        + df.iloc[start:start+10].to_html() + '</div>'))\n",
    "            # Update the dimensions label\n",
    "            dimensions_label.value = f'<h4>Dimensions: {df.shape}</h4>'\n",
    "\n",
    "    # Function to show search results\n",
    "    def show_search(button_instance=None):\n",
    "        nonlocal df\n",
    "        if search_input.value:\n",
    "            if not_checkbox.value:\n",
    "                df = df[~df[column_dropdown.value].astype(str).str.contains(search_input.value)]\n",
    "            else:\n",
    "                df = df[df[column_dropdown.value].astype(str).str.contains(search_input.value)]\n",
    "        show_output()\n",
    "    \n",
    "    # Function to show description\n",
    "    def show_description(button_instance=None):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            if df is not None:\n",
    "                desc_df = df.describe()\n",
    "                desc_df = desc_df.applymap(lambda x: '{:.0f}'.format(x) if x == int(x) else '{:.4f}'.format(x))\n",
    "                display(HTML('<div style=\"overflow-x: auto; white-space: nowrap;\">' \n",
    "                        + desc_df.to_html() + '</div>'))\n",
    "            else:\n",
    "                display(HTML('<p style=\"color: red;\">Please first select \"Show\".</p>'))\n",
    "\n",
    "    # Get list of dataframe names\n",
    "    df_names = list(dataframes.keys())\n",
    "    \n",
    "    # Create dropdown and show button\n",
    "    dropdown = widgets.Dropdown(options=df_names)\n",
    "    show_button = widgets.Button(description='Show')\n",
    "\n",
    "    # Display UI elements\n",
    "    title = widgets.HTML('<h2 style=\"text-align: center;\">Other CSVs</h2>')\n",
    "    box_layout = widgets.Layout(display='flex', justify_content='center')\n",
    "    display(\n",
    "        widgets.VBox(\n",
    "            [\n",
    "                title, widgets.HBox([dropdown, show_button, describe_button], layout=box_layout),\n",
    "                widgets.HBox([not_checkbox, column_dropdown, search_input, search_button], layout=box_layout),\n",
    "                output,\n",
    "                widgets.HBox([dimensions_label], layout=widgets.Layout(justify_content='flex-start')),\n",
    "                widgets.HBox([head_button, prev_button, next_button, tail_button], layout=box_layout)\n",
    "            ],\n",
    "            layout=box_layout\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Attach event handlers to buttons\n",
    "    show_button.on_click(show_df)\n",
    "    describe_button.on_click(show_description)\n",
    "    head_button.on_click(on_head_button_clicked)\n",
    "    prev_button.on_click(on_prev_button_clicked)\n",
    "    next_button.on_click(on_next_button_clicked)\n",
    "    tail_button.on_click(on_tail_button_clicked)\n",
    "    search_button.on_click(show_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_other_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie viele ... gibt es? (Einzigartige Werte)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Bahnen (linie) gibt es in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_type_of_line(save=False):\n",
    "    unique_linien = set()\n",
    "    for df in fahrzeiten_dfs.values():\n",
    "        unique_linien.update(df['linie'].unique())\n",
    "\n",
    "    # Count the number of each type of line\n",
    "    tram_count = len([linie for linie in unique_linien if 2 <= linie <= 17])\n",
    "    bus_count = len([linie for linie in unique_linien if 29 <= linie <= 916])\n",
    "    bergbahn_count = len([linie for linie in unique_linien if 18 <= linie <= 28])\n",
    "    other_count = len(unique_linien) - tram_count - bus_count - bergbahn_count\n",
    "    \n",
    "    # Create a DataFrame with counts and corresponding labels\n",
    "    df_linien_counts = pd.DataFrame({\n",
    "        'Type of Line': ['Tram', 'Bus', 'Bergbahn', 'Other'],\n",
    "        'Count': [tram_count, bus_count, bergbahn_count, other_count]\n",
    "    })\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    bars = sns.barplot(x=df_linien_counts['Type of Line'], y=df_linien_counts['Count'], ax=ax, palette='Set2', zorder=2)\n",
    "    \n",
    "    # Add the counts above the bars\n",
    "    for bar in bars.patches:\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{int(bar.get_height())}', ha='center', va='bottom')\n",
    "\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Count of Each Type of Line in Fahrzeiten CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    plt.xlabel('Type of Line')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(axis='y', zorder=1)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/type_of_line_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_type_of_line(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Es gibt 73 Linien. Siehe type_of_line_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Gibt es mehrere Bahnunternehmen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bahnhofseigner_counts = passagierfrequenz_df[\"isb_gi\"].value_counts().to_dict()\n",
    "df_bahnhofseigner_counts = pd.DataFrame(\n",
    "    bahnhofseigner_counts.items(), columns=[\"Station Owner\", \"Number of Stations\"]\n",
    ")\n",
    "\n",
    "expanded_df = passagierfrequenz_df[\"evu_ef_itf\"].str.split(',', expand=True).stack().str.strip()\n",
    "evu_counts = expanded_df.value_counts().to_dict()\n",
    "df_evu_counts = pd.DataFrame(\n",
    "    evu_counts.items(), columns=[\"Company\", \"Number of Stations\"]\n",
    ")\n",
    "\n",
    "max_value = max(df_bahnhofseigner_counts[\"Number of Stations\"].max(), df_evu_counts[\"Number of Stations\"].max()) + 80\n",
    "\n",
    "def create_bar_chart_bahnhofseigner_counts(save=False):\n",
    "    # Create the horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = sns.barplot(\n",
    "        y=df_bahnhofseigner_counts[\"Station Owner\"],\n",
    "        x=df_bahnhofseigner_counts[\"Number of Stations\"],\n",
    "        order=df_bahnhofseigner_counts[\"Station Owner\"].value_counts().index,\n",
    "        ax=ax,\n",
    "        palette='Set2',\n",
    "        zorder=2\n",
    "    )\n",
    "    ax.set_xlim(0, max_value)\n",
    "\n",
    "    # Add the number of stations on top of each bar\n",
    "    for bar in bars.patches:\n",
    "        ax.text(\n",
    "            bar.get_width(),\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f'{int(bar.get_width())}',\n",
    "            ha='left',\n",
    "            va='center'\n",
    "        )\n",
    "\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        ticker.FuncFormatter(lambda x, pos: \"{:,.0f}\".format(x))\n",
    "    )\n",
    "    plt.title(\"Number of Stations per Owner in Passagierfrequenz CSV\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"Number of Stations\")\n",
    "    plt.grid(axis=\"x\", zorder=1)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"../figures/exploration/bahnhofseigner_count.png\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        \n",
    "def create_bar_chart_eisenbahnunternehmen_counts(save=False):\n",
    "    # Create the horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = sns.barplot(\n",
    "        y=df_evu_counts[\"Company\"],\n",
    "        x=df_evu_counts[\"Number of Stations\"],\n",
    "        ax=ax,\n",
    "        palette='Set2',\n",
    "        zorder=2\n",
    "    )\n",
    "    ax.set_xlim(0, max_value)\n",
    "    \n",
    "    # Add the number of stations on top of each bar\n",
    "    for bar in bars.patches:\n",
    "        ax.text(\n",
    "            bar.get_width(),\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f'{int(bar.get_width())}',\n",
    "            ha='left',\n",
    "            va='center'\n",
    "        )\n",
    "\n",
    "    ax.xaxis.set_major_formatter(\n",
    "        ticker.FuncFormatter(lambda x, pos: \"{:,.0f}\".format(x))\n",
    "    )\n",
    "    plt.title(\"Number of Stations per Company in Passagierfrequenz CSV\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(\"Number of Stations\")\n",
    "    plt.grid(axis=\"x\", zorder=1)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(\"../figures/exploration/eisenbahnunternehmen_count.png\", bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "# create_bar_chart_bahnhofseigner_counts(save=True)\n",
    "# create_bar_chart_eisenbahnunternehmen_counts(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe bahnhofseigner_count.png und bahnhofs_eisenbahnunternehmen_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Haltestellen gibt es in Haltestellen.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Haltestellen: 769\n"
     ]
    }
   ],
   "source": [
    "print(f'Unique Haltestellen: {len(haltestelle_df[\"halt_id\"].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Es gibt 769 Haltestellen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Städte gibt es in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Einzigartige Städte: 50\n",
      "['Adliswil', 'Aesch bei Maur', 'Benglen', 'Bergdietikon', 'Binz bei Maur', 'Birmensdorf ZH', 'Dietikon', 'Dübendorf', 'Ebmatingen', 'Effretikon', 'Fahrweid', 'Forch', 'Fällanden', 'Geroldswil', 'Glanzenberg', 'Glattbrugg', 'Glattpark', 'Gockhausen', 'Itschnach', 'Kilchberg ZH', 'Killwangen', 'Kindhausen AG', 'Kloten Balsberg', 'Küsnacht ZH', 'Maur', 'Oberengstringen', 'Oetwil a.d.L.', 'Oetwil an der Limmat', 'Pfaffhausen', 'Rümlang', 'Rüschlikon', 'Scheuren', 'Schlieren', 'Schwerzenbach ZH', 'Spreitenbach', 'Unterengstringen', 'Urdorf', 'Urdorf Weihermatt', 'Volketswil', 'Waldburg', 'Wallisellen', 'Weiningen ZH', 'Wädenswil', 'Zch', 'Zollikerb.', 'Zollikerberg', 'Zollikon', 'Zumikon', 'Zürich', 'Zürich Flughafen']\n"
     ]
    }
   ],
   "source": [
    "unique_staedte = set()\n",
    "for df in fahrzeiten_dfs.values():\n",
    "    halt_id_von = df['halt_id_von'].unique()\n",
    "    halt_id_nach = df['halt_id_nach'].unique()\n",
    "    halt_id = np.unique(np.concatenate((halt_id_von, halt_id_nach)))\n",
    "    haltestellen_name = haltestelle_df[haltestelle_df['halt_id'].isin(halt_id)]['halt_lang'].unique()\n",
    "    stadt_name = map(lambda x: x.split(',')[0], haltestellen_name)\n",
    "    unique_staedte.update(stadt_name)\n",
    "unique_staedte = sorted(unique_staedte)\n",
    "\n",
    "print(f'Einzigartige Städte: {len(unique_staedte)}')\n",
    "print(unique_staedte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Es gibt zwar laut Ausgabe 50 Städte, aber manche Einträge sind anders geschriebene Städte, die eigentlich die gleiche Stadt sind. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Einträge gibt es in der Passagierfrequenz CSV pro Stadt pro Kategorie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_avg_passenger_counts(save=False, values=10):\n",
    "    # Combine the two dataframes\n",
    "    combined = passagierfrequenz_df[passagierfrequenz_df[\"jahr_annee_anno\"].isin([2018, 2022])].copy()\n",
    "\n",
    "    # Create a dictionary of categories\n",
    "    categories = {\n",
    "        'dtv_tjm_tgm': 'Whole Week',\n",
    "        'dwv_tmjo_tfm': 'Work Week',\n",
    "        'dnwv_tmjno_tmgnl': 'Non-Work Days and Holidays'\n",
    "    }\n",
    "\n",
    "    # Create a bar chart for each category\n",
    "    for category, category_name in categories.items():\n",
    "        \n",
    "        # Create a new column that contains the maximum value for each station\n",
    "        combined['max_value'] = combined.groupby('bahnhof_gare_stazione')[category].transform('max')\n",
    "\n",
    "        # Identify the top stations\n",
    "        top_stations = combined.sort_values('max_value', ascending=False)['bahnhof_gare_stazione'].unique()[:values]\n",
    "\n",
    "        # Filter the original data for the top stations\n",
    "        combined_top = combined[combined['bahnhof_gare_stazione'].isin(top_stations)]\n",
    "        combined_top['jahr_annee_anno'] = combined_top['jahr_annee_anno'].astype(str)\n",
    "        # Specify the order of the stations\n",
    "        combined_top['bahnhof_gare_stazione'] = pd.Categorical(combined_top['bahnhof_gare_stazione'], categories=top_stations.tolist(), ordered=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(y=combined_top['bahnhof_gare_stazione'], x=combined_top[category], hue=combined_top['jahr_annee_anno'], ax=ax, palette='Set2')\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "        plt.title(f'Top {values} Most Frequent Stations in Passagierfrequenz CSV ({category_name})')\n",
    "        plt.ylabel('')\n",
    "        plt.xlabel('Average Number of Passengers')\n",
    "        plt.grid(axis='x')\n",
    "\n",
    "        # Modify the legend name and position\n",
    "        ax.legend(title='Year', loc='lower right')\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(f'../figures/exploration/avg_passenger_count_per_station_{category}.png', bbox_inches='tight')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n"
     ]
    }
   ],
   "source": [
    "# pd.options.mode.chained_assignment = None\n",
    "# create_bar_chart_avg_passenger_counts(save=True, values=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_avg_passenger_counts_v2(save=False, values=10):\n",
    "    # Fill the missing values in the jahr_annee_anno column with 2018\n",
    "    temp = passagierfrequenz_df.copy()\n",
    "    \n",
    "    temp['jahr_annee_anno'].fillna(2018, inplace=True)\n",
    "    \n",
    "    # Combine the two dataframes\n",
    "    combined = temp[temp[\"jahr_annee_anno\"].isin([2018, 2022])].copy()\n",
    "\n",
    "    # Create a dictionary of categories\n",
    "    categories = {\n",
    "        'dtv_tjm_tgm': 'Whole Week',\n",
    "        'dwv_tmjo_tfm': 'Work Week',\n",
    "        'dnwv_tmjno_tmgnl': 'Non-Work Days and Holidays'\n",
    "    }\n",
    "\n",
    "    # Create a bar chart for each category\n",
    "    for category, category_name in categories.items():\n",
    "        # Create a new column that contains the maximum value for each station\n",
    "        combined['max_value'] = combined.groupby('bahnhof_gare_stazione')[category].transform('max')\n",
    "\n",
    "        # Identify the top stations\n",
    "        top_stations = combined.sort_values('max_value', ascending=False)['bahnhof_gare_stazione'].unique()[:values]\n",
    "\n",
    "        # Filter the original data for the top stations\n",
    "        combined_top = combined[combined['bahnhof_gare_stazione'].isin(top_stations)]\n",
    "        combined_top['jahr_annee_anno'] = combined_top['jahr_annee_anno'].astype(str)\n",
    "        # Specify the order of the stations\n",
    "        combined_top['bahnhof_gare_stazione'] = pd.Categorical(combined_top['bahnhof_gare_stazione'], categories=top_stations.tolist(), ordered=True)\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        sns.barplot(y=combined_top['bahnhof_gare_stazione'], x=combined_top[category], hue=combined_top['jahr_annee_anno'], ax=ax, palette='Set2')\n",
    "        ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "        plt.title(f'Top {values} Most Frequent Stations in Passagierfrequenz CSV ({category_name})')\n",
    "        plt.ylabel('')\n",
    "        plt.xlabel('Average Number of Passengers')\n",
    "        plt.grid(axis='x')\n",
    "\n",
    "        # Modify the legend name and position\n",
    "        ax.legend(title='Year', loc='lower right')\n",
    "\n",
    "        if save:\n",
    "            plt.savefig(f'../figures/exploration/avg_passenger_count_per_station_{category}_v2.png', bbox_inches='tight')\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  grouped_vals = vals.groupby(grouper)\n"
     ]
    }
   ],
   "source": [
    "# create_bar_chart_avg_passenger_counts_v2(save=True, values=20)\n",
    "# pd.options.mode.chained_assignment = 'warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe avg_passenger_count_per_station_[...].png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele aktive/inaktive Haltestellen/Haltepunkte gibt es in Haltestelle.csv und Haltepunkt.csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pie_chart_active_inactive(save=False):\n",
    "    labels = ['Active', 'Inactive']\n",
    "    explode = (0, 0.05)\n",
    "    colors = sns.color_palette('Set2')\n",
    "\n",
    "    def custom_autopct(pct):\n",
    "        return ('%1.1f%%' % pct) if pct > 0 else ''\n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Pie chart for Haltestellen\n",
    "    sizes = [haltestelle_df['halt_ist_aktiv'].sum(), (~haltestelle_df['halt_ist_aktiv']).sum()]\n",
    "    axs[0].pie(sizes, startangle=90, autopct=custom_autopct, explode=explode, colors=colors)\n",
    "    axs[0].set_title('Haltestellen')\n",
    "    axs[0].axis('equal')\n",
    "\n",
    "    # Pie chart for Haltepunkte\n",
    "    sizes = [haltepunkt_df['halt_punkt_ist_aktiv'].sum(), (~haltepunkt_df['halt_punkt_ist_aktiv']).sum()]\n",
    "    axs[1].pie(sizes, startangle=90, autopct=custom_autopct, explode=explode, colors=colors)\n",
    "    axs[1].set_title('Haltepunkte')\n",
    "    axs[1].axis('equal')\n",
    "\n",
    "    # Set main title and legend\n",
    "    fig.suptitle(f'Percentage of Active and Inactive ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})', fontsize=16)\n",
    "    fig.legend(labels, loc='upper center', bbox_to_anchor=(0.5, 0.9))\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/percentage_active_inactive.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pie_chart_active_inactive(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "In Haltestellen.csv sind 100% der Haltestellen aktiv. In Haltepunkt.csv ist es verteilter. Siehe percentage_active_inactive.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leere/Falsche Einträge\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele leere Einträge gibt es pro Spalte in einer CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_empty_cells_percentage(df, save=False, df_name='placeholder'):\n",
    "    empty_cells_percentages = {column: (sum_val := df[column].replace('', np.nan).isnull().sum(), sum_val / len(df)) for column in df.columns}\n",
    "\n",
    "    # Check if there are any empty cells\n",
    "    if all(num == 0 for num, _ in empty_cells_percentages.values()):\n",
    "        print(f\"There are no empty cells in any column of the {df_name} DataFrame.\")\n",
    "        return\n",
    "\n",
    "    # Convert the dictionary to a DataFrame for easier plotting\n",
    "    df_empty_cells = pd.DataFrame(empty_cells_percentages, index=['Empty Cells', 'Percentage']).T\n",
    "    df_empty_cells = df_empty_cells.sort_values('Percentage', ascending=True)\n",
    "\n",
    "    # Create the bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=df_empty_cells['Percentage'] * 100, y=df_empty_cells.index, palette='Set2', zorder=2)\n",
    "    if df_name.startswith('Fahrzeiten_SOLL_IST') or df_name == 'haltepunkt' or df_name == 'haltestelle':\n",
    "        plt.title(f'Empty Cells in Each Column of the {df_name} CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    else:\n",
    "        plt.title(f'Empty Cells in Each Column of the {df_name} CSV')\n",
    "    plt.xlabel('Percentage (%)')\n",
    "    plt.grid(axis='x', zorder=1)\n",
    "    plt.xlim(0, 100)\n",
    "    plt.xticks(np.arange(0, 101, 5))\n",
    "\n",
    "    # Display the number of empty cells next to the bars\n",
    "    for i, (num, perc) in enumerate(zip(df_empty_cells['Empty Cells'], df_empty_cells['Percentage'] * 100)):\n",
    "        if num > 0:\n",
    "            plt.text(perc, i, int(num), va='center')\n",
    "\n",
    "    if save:\n",
    "        if df_name.startswith('Fahrzeiten_SOLL_IST') or df_name == 'haltepunkt' or df_name == 'haltestelle':\n",
    "            plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/empty_cells_percentage_{df_name}.png', bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(f'../figures/exploration/empty_cells_percentage_{df_name}.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no empty cells in any column of the haltestelle DataFrame.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "# create_bar_chart_empty_cells_percentage(passagierfrequenz_df, save=True, df_name='passagierfrequenz')\n",
    "create_bar_chart_empty_cells_percentage(haltepunkt_df, save=True, df_name='haltepunkt')\n",
    "create_bar_chart_empty_cells_percentage(haltestelle_df, save=True, df_name='haltestelle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220102_20220108.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220109_20220115.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220116_20220122.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220123_20220129.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220130_20220205.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220206_20220212.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220213_20220219.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220220_20220226.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220227_20220305.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220306_20220312.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220313_20220319.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220320_20220326.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220327_20220402.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220403_20220409.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220410_20220416.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220417_20220423.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220424_20220430.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220501_20220507.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220508_20220514.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220515_20220521.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220522_20220528.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220529_20220604.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220605_20220611.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220612_20220618.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220619_20220625.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220626_20220702.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220703_20220709.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220710_20220716.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220717_20220723.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220724_20220730.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220731_20220806.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220807_20220813.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220814_20220820.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220821_20220827.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220828_20220903.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220904_20220910.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220911_20220917.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220918_20220924.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20220925_20221001.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221002_20221008.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221009_20221015.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221016_20221022.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221023_20221029.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221030_20221105.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221106_20221112.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221113_20221119.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221120_20221126.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221127_20221203.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221204_20221210.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221211_20221217.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221218_20221224.csv DataFrame.\n",
      "There are no empty cells in any column of the Fahrzeiten_SOLL_IST_20221225_20221231.csv DataFrame.\n"
     ]
    }
   ],
   "source": [
    "for df_name, df in fahrzeiten_dfs.items():\n",
    "    create_bar_chart_empty_cells_percentage(df, save=True, df_name=df_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "In haltestelle.csv und allen Fahrzeiten CSVs gibt es keine leeren Einträge. In haltepunkt.csv und passagierfrequenz.csv schon. Siehe empty_cells_percentage_[...].png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele falsche Einträge gibt es pro Spalte in einer CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values(df, condition, message):\n",
    "    if not condition(df).all():\n",
    "        print(message)\n",
    "        print('----------------------------------------------')\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def count_values(df, condition):\n",
    "    return (~condition(df)).sum()\n",
    "\n",
    "grouped_conditions = {\n",
    "    'Ungrouped': {\n",
    "        'richtung contains values other than 1 or 2.': lambda df: df['richtung'].isin([1, 2]),\n",
    "        'datum_von is greater than datum_nach.': lambda df: pd.to_datetime(df['datum_von'], format='%d.%m.%y') <= pd.to_datetime(df['datum_nach'], format='%d.%m.%y'),\n",
    "        'seq_von is not 1 smaller than seq_nach.': lambda df: df['seq_von'] + 1 == df['seq_nach'],\n",
    "    },\n",
    "    'Between 0 and 86399': {\n",
    "        'soll_an_von is not between 0 and 86399.': lambda df: (0 <= df['soll_an_von']) & (df['soll_an_von'] <= 86399),\n",
    "        'soll_an_nach is not between 0 and 86399.': lambda df: (0 <= df['soll_an_nach']) & (df['soll_an_nach'] <= 86399),\n",
    "    },\n",
    "    'Less or equal': {\n",
    "        'ist_an_von is greater than ist_ab_von.': lambda df: df['ist_an_von'] <= df['ist_ab_von'],\n",
    "        'ist_an_nach1 is greater than ist_ab_nach.': lambda df: df['ist_an_nach1'] <= df['ist_ab_nach'],\n",
    "        'soll_an_von is greater than soll_ab_von.': lambda df: df['soll_an_von'] <= df['soll_ab_von'],\n",
    "        'soll_an_nach is greater than soll_ab_nach.': lambda df: df['soll_an_nach'] <= df['soll_ab_nach'],\n",
    "    },\n",
    "}\n",
    "\n",
    "grouped_count_conditions = {\n",
    "    'Greater than 86399': {\n",
    "        'Entries in ist_an_von/ist_an_nach1 greater than 86399': lambda df: (df['ist_an_von'] <= 86399) & (df['ist_an_nach1'] <= 86399),\n",
    "        'Entries in ist_ab_von/ist_ab_nach greater than 86399': lambda df: (df['ist_ab_von'] <= 86399) & (df['ist_ab_nach'] <= 86399),\n",
    "        'Entries in soll_ab_von/soll_ab_nach greater than 86399': lambda df: (df['soll_ab_von'] <= 86399) & (df['soll_ab_nach'] <= 86399),\n",
    "    },\n",
    "    'Less than 0': {\n",
    "        'Entries in ist_an_von/ist_an_nach1 less than 0': lambda df: (df['ist_an_von'] >= 0) & (df['ist_an_nach1'] >= 0),\n",
    "        'Entries in ist_ab_von/ist_ab_nach less than 0': lambda df: (df['ist_ab_von'] >= 0) & (df['ist_ab_nach'] >= 0),\n",
    "    },\n",
    "}\n",
    "\n",
    "def check_fahrzeiten_csvs():\n",
    "    grouped_count_results = {group: {key: 0 for key in count_conditions.keys()} for group, count_conditions in grouped_count_conditions.items()}\n",
    "    all_conditions_met = True\n",
    "\n",
    "    for df in fahrzeiten_dfs.values():\n",
    "        for group, conditions in grouped_conditions.items():\n",
    "            for message, condition in conditions.items():\n",
    "                if check_values(df, condition, message):\n",
    "                    all_conditions_met = False\n",
    "                    break\n",
    "        for group, count_conditions in grouped_count_conditions.items():\n",
    "            for message, condition in grouped_count_conditions[group].items():\n",
    "                grouped_count_results[group][message] += count_values(df, condition)\n",
    "            \n",
    "    if all_conditions_met:\n",
    "        print(f\"All conditions are met\")\n",
    "        print('==============================================')\n",
    "\n",
    "    for group, count_results in grouped_count_results.items():\n",
    "        print(f'{group}:')\n",
    "        print('----------------------------------------------')\n",
    "        for message, count in count_results.items():\n",
    "            print(f'{message}: {count}')\n",
    "        print('==============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_fahrzeiten_csvs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versuch zu schauen ob Tabellen matchen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # halt_punkt_id_von and halt_punkt_id_nach from the fahrzeiten_dfs correspond to the haltpunkt_df['halt_punkt_id'] column\n",
    "# # hald_id_von and halt_id_nach from the fahrzeiten_dfs correspond to the haltestelle_df['halt_id'] column\n",
    "# # halt_id from the haltepunkt_df corresponds to the haltestelle_df['halt_id'] column\n",
    "# # halt_diva_von and halt_diva_nach from the fahrzeiten_dfs correspond to the haltestelle_df['halt_diva'] column and it has to be the same combination with the halt_id_von and halt_id_nach to the halt_id and halt_diva columns in the haltestelle_df\n",
    "# # halt_punkt_diva_von and halt_punkt_diva_nach from the fahrzeiten_dfs correspond to the haltepunkt_df['halt_punkt_diva'] column and it has to be the same combination with the halt_punkt_id_von and halt_punkt_id_nach to the halt_punkt_id and halt_punkt_diva columns in the haltepunkt_df\n",
    "# # halt_kurz_von1 and halt_kurz_nach1 from the fahrzeiten_dfs correspond to the haltestelle_df['halt_kurz'] column and it has to be the same combination with the halt_id_von and halt_id_nach to the halt_id and halt_kurz columns in the haltestelle_df\n",
    "\n",
    "# # Create a dictionary: {halt_punkt_id: (halt_punkt_diva, halt_id)}\n",
    "# # And a dictionary: {halt_id: (halt_diva, halt_kurz)}\n",
    "# halt_punkt_id_diva_id_dict = {}\n",
    "# halt_id_diva_kurz_dict = {}\n",
    "# for _, row in haltepunkt_df.iterrows():\n",
    "#     halt_punkt_id_diva_id_dict[row['halt_punkt_id']] = (row['halt_punkt_diva'], row['halt_id'])\n",
    "# for _, row in haltestelle_df.iterrows():\n",
    "#     halt_id_diva_kurz_dict[row['halt_id']] = (row['halt_diva'], row['halt_kurz'])\n",
    "    \n",
    "# # Now check the conditions above\n",
    "# all_conditions_met = True\n",
    "# for df in fahrzeiten_dfs.values():\n",
    "#     halt_punkt_id_von_diva_id = df[['halt_punkt_id_von', 'halt_punkt_diva_von', 'halt_id_von']].drop_duplicates()\n",
    "#     halt_punkt_id_nach_diva_id = df[['halt_punkt_id_nach', 'halt_punkt_diva_nach', 'halt_id_nach']].drop_duplicates()\n",
    "#     halt_id_von_diva_kurz = df[['halt_id_von', 'halt_diva_von', 'halt_kurz_von1']].drop_duplicates()\n",
    "#     halt_id_nach_diva_kurz = df[['halt_id_nach', 'halt_diva_nach', 'halt_kurz_nach1']].drop_duplicates()\n",
    "    \n",
    "#     if not halt_punkt_id_von_diva_id.apply(lambda row: halt_punkt_id_diva_id_dict[row['halt_punkt_id_von']] == (row['halt_punkt_diva_von'], row['halt_id_von']), axis=1).all():\n",
    "#         print('halt_punkt_id_von and halt_punkt_diva_von and halt_id_von are not consistent')\n",
    "#         print('----------------------------------------------')\n",
    "#         all_conditions_met = False\n",
    "#     if not halt_punkt_id_nach_diva_id.apply(lambda row: halt_punkt_id_diva_id_dict[row['halt_punkt_id_nach']] == (row['halt_punkt_diva_nach'], row['halt_id_nach']), axis=1).all():\n",
    "#         print('halt_punkt_id_nach and halt_punkt_diva_nach and halt_id_nach are not consistent')\n",
    "#         print('----------------------------------------------')\n",
    "#         all_conditions_met = False\n",
    "#     if not halt_id_von_diva_kurz.apply(lambda row: halt_id_diva_kurz_dict[row['halt_id_von']] == (row['halt_diva_von'], row['halt_kurz_von1']), axis=1).all():\n",
    "#         print('halt_id_von and halt_diva_von and halt_kurz_von1 are not consistent')\n",
    "#         print('----------------------------------------------')\n",
    "#         all_conditions_met = False\n",
    "#     if not halt_id_nach_diva_kurz.apply(lambda row: halt_id_diva_kurz_dict[row['halt_id_nach']] == (row['halt_diva_nach'], row['halt_kurz_nach1']), axis=1).all():\n",
    "#         print('halt_id_nach and halt_diva_nach and halt_kurz_nach1 are not consistent')\n",
    "#         print('----------------------------------------------')\n",
    "#         all_conditions_met = False\n",
    "        \n",
    "# if all_conditions_met:\n",
    "#     print(f\"All conditions are met\")\n",
    "    # print('==============================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Die Einträge in den Fahrzeiten CSVs sind alle korrekt. Es gibt Einträge, die den Hinweisen entsprechen.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wie oft ist ... in den Fahrzeiten CSVs?\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie oft ist eine Bahn (linie) in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_linien_counts(save=False, values=10):\n",
    "    linien_counts = {}\n",
    "\n",
    "    for df in fahrzeiten_dfs.values():\n",
    "        size = df.groupby('linie').size()\n",
    "        for linie, count in size.items():\n",
    "            if linie in linien_counts:\n",
    "                linien_counts[linie] += count\n",
    "            else:\n",
    "                linien_counts[linie] = count\n",
    "                \n",
    "    df_linien_counts = pd.DataFrame(linien_counts.items(), columns=['Line', 'Count'])\n",
    "    \n",
    "    if values > df_linien_counts.shape[0]:\n",
    "        values = df_linien_counts.shape[0]\n",
    "    \n",
    "    df_linien_counts = df_linien_counts.sort_values('Count', ascending=False).head(values)\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=df_linien_counts['Line'], y=df_linien_counts['Count'], order=df_linien_counts['Line'], ax=ax, palette='Set2', zorder=2)\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Top {values} Most Frequent Lines in Fahrzeiten CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    plt.xlabel('Line')\n",
    "    plt.ylabel('Amount of Entries')\n",
    "    plt.grid(axis='y', zorder=1)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/linien_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_linien_counts(save=True, values=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe linien_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie oft ist eine Haltestelle in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_haltestellen_counts(save=False, values=10):\n",
    "    haltestellen_counts = {}\n",
    "\n",
    "    for df in fahrzeiten_dfs.values():\n",
    "        size = df.groupby('halt_id_von').size()\n",
    "        for halt, count in size.items():\n",
    "            haltestellen_name = haltestelle_df[haltestelle_df['halt_id'] == halt]['halt_lang'].values[0]\n",
    "            if halt in haltestellen_counts:\n",
    "                haltestellen_counts[haltestellen_name] += count\n",
    "            else:\n",
    "                haltestellen_counts[haltestellen_name] = count\n",
    "                \n",
    "    df_haltestellen_counts = pd.DataFrame(haltestellen_counts.items(), columns=['Haltestelle', 'Count'])\n",
    "    df_haltestellen_counts = df_haltestellen_counts.sort_values('Count', ascending=False).head(values)\n",
    "\n",
    "    # Create the horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=df_haltestellen_counts['Count'], y=df_haltestellen_counts['Haltestelle'], order=df_haltestellen_counts['Haltestelle'], ax=ax, palette='Set2', zorder=2)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Top {values} Most Frequent Bus/Train Stops in Fahrzeiten CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    plt.xlabel('Amount of Entries')\n",
    "    plt.ylabel('')\n",
    "    plt.grid(axis='x', zorder=1)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/haltestellen_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_haltestellen_counts(save=True, values=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe haltestellen_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie oft ist eine Stadt in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_staedte_count(save=False, values=10):\n",
    "    staedte_counts = {}\n",
    "    \n",
    "    for df in fahrzeiten_dfs.values():\n",
    "        halt_diva = df['halt_id_von'].unique()\n",
    "        haltestellen_name = haltestelle_df[haltestelle_df['halt_id'].isin(halt_diva)]['halt_lang'].unique()\n",
    "        stadt_name = map(lambda x: x.split(',')[0], haltestellen_name)\n",
    "        for stadt in stadt_name:\n",
    "            if stadt in staedte_counts:\n",
    "                staedte_counts[stadt] += 1\n",
    "            else:\n",
    "                staedte_counts[stadt] = 1\n",
    "                \n",
    "    df_staedte_counts = pd.DataFrame(staedte_counts.items(), columns=['Stadt', 'Count'])\n",
    "    df_staedte_counts = df_staedte_counts.sort_values('Count', ascending=False).head(values)\n",
    "    \n",
    "    # Create the horizontal bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=df_staedte_counts['Count'], y=df_staedte_counts['Stadt'], order=df_staedte_counts['Stadt'], ax=ax, palette='Set2', zorder=2)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Top {values} Most Frequent Cities in Fahrzeiten CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    plt.xlabel('Amount of Entries')\n",
    "    plt.ylabel('')\n",
    "    plt.xticks(np.arange(0, 24001, 2000))\n",
    "    plt.grid(axis='x', zorder=1)\n",
    "\n",
    "    # Add the number of the value next to the bar\n",
    "    for i, v in enumerate(df_staedte_counts['Count']):\n",
    "        ax.text(v + 0.5, i, str(v), color='black', va='center')\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/staedte_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_staedte_count(save=True, values=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe staedte_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Einträge gibt es pro Betriebsdatum in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "betriebsdatum_counts = {}\n",
    "\n",
    "for df in fahrzeiten_dfs.values():\n",
    "    size = df.groupby('betriebsdatum').size()\n",
    "    for betriebsdatum, count in size.items():\n",
    "        if betriebsdatum in betriebsdatum_counts:\n",
    "            betriebsdatum_counts[betriebsdatum] += count\n",
    "        else:\n",
    "            betriebsdatum_counts[betriebsdatum] = count\n",
    "\n",
    "df_betriebsdatum_counts = pd.DataFrame(betriebsdatum_counts.items(), columns=['Betriebsdatum', 'Count'])\n",
    "df_betriebsdatum_counts = df_betriebsdatum_counts.sort_values('Count', ascending=False)\n",
    "df_betriebsdatum_counts['Betriebsdatum'] = pd.to_datetime(df_betriebsdatum_counts['Betriebsdatum'], format='%d.%m.%y')\n",
    "\n",
    "def show_betriebsdatum_counts():\n",
    "    # Erstellen einer Dash-App\n",
    "    app = dash.Dash(__name__)\n",
    "\n",
    "    # Layout des Dash-Dashboards\n",
    "    app.layout = html.Div([\n",
    "        html.Div([\n",
    "            html.Button(f\"Overview\\n{df_betriebsdatum_counts['Count'].sum():,.0f}\",\n",
    "                        id='button-overview', n_clicks=1, style={'display': 'inline-block', 'white-space': 'pre-line', 'width': '10%'}),\n",
    "            html.Div([\n",
    "                html.Button(f\"{calendar.month_name[i]}\\n{df_betriebsdatum_counts[df_betriebsdatum_counts['Betriebsdatum'].dt.month == i]['Count'].sum():,.0f}\",\n",
    "                            id=f'button-{i}', n_clicks=0, style={'display': 'inline-block', 'white-space': 'pre-line', 'width': '8.33%'})\n",
    "                for i in range(1, 13)\n",
    "            ], style={'text-align': 'center'}),\n",
    "        ], style={'text-align': 'center'}),\n",
    "        dcc.Graph(id='calendar-plot'),\n",
    "    ], className='container')\n",
    "\n",
    "    @app.callback(\n",
    "        Output('calendar-plot', 'figure'),\n",
    "        [Input('button-overview', 'n_clicks')] + [Input(f'button-{i}', 'n_clicks') for i in range(1, 13)]\n",
    "    )\n",
    "    def update_calendar(n_overview, *n_clicks):\n",
    "        ctx = dash.callback_context\n",
    "        if not ctx.triggered:\n",
    "            month_num = 0\n",
    "        else:\n",
    "            trigger_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "            if trigger_id == 'button-overview':\n",
    "                month_num = 0\n",
    "            else:\n",
    "                month_num = int(trigger_id.split('-')[-1])\n",
    "\n",
    "        if month_num == 0:\n",
    "            df_grouped = df_betriebsdatum_counts.groupby(df_betriebsdatum_counts['Betriebsdatum'].dt.month)['Count'].sum()\n",
    "            fig = {\n",
    "                'data': [\n",
    "                    {'x': [calendar.month_name[i] for i in df_grouped.index], 'y': df_grouped, 'type': 'bar', 'name': 'Anzahl Zeilen'},\n",
    "                ],\n",
    "                'layout': {\n",
    "                    'title': 'Amount of Entries for every Month in Fahrzeiten CSVs',\n",
    "                    'xaxis': {'title': 'Month'},\n",
    "                    'yaxis': {'title': 'Entries'}\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            filtered_df = df_betriebsdatum_counts[df_betriebsdatum_counts['Betriebsdatum'].dt.month == month_num]\n",
    "            fig = {\n",
    "                'data': [\n",
    "                    {'x': filtered_df['Betriebsdatum'], 'y': filtered_df['Count'], 'type': 'bar', 'name': 'Anzahl Zeilen'},\n",
    "                ],\n",
    "                'layout': {\n",
    "                    'title': f'Amount of Entries in {calendar.month_name[month_num]} in Fahrzeiten CSVs',\n",
    "                    'xaxis': {'title': 'Day'},\n",
    "                    'yaxis': {'title': 'Entries'}\n",
    "                }\n",
    "            }\n",
    "\n",
    "        return fig\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_betriebsdatum_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe Interaktion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele Fahrzeuge gibt es in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl Fahrzeuge: 576\n",
      "{2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2059, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 10264, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 10276, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 10312, 10310, 10313, 10331, 10332, 10333, 10334, 10335, 10336, 10337, 10338, 10340, 10341, 10342, 10343, 10344, 10345, 10346, 10347, 10203, 10208, 10401, 10402, 10403, 10404, 10405, 10406, 10407, 10408, 10409, 10410, 10411, 10412, 10413, 10414, 10415, 10416, 10417, 10418, 10419, 10420, 10421, 10422, 10423, 10424, 10425, 10426, 10427, 10428, 10429, 10430, 10431, 2073, 10440, 10441, 10442, 10443, 10444, 10445, 10446, 10447, 10448, 10450, 10451, 10452, 10453, 10454, 10455, 10456, 10457, 10458, 10459, 10460, 10461, 10462, 10463, 10464, 10465, 10466, 10467, 10468, 10469, 10470, 10471, 10472, 10500, 2087, 10502, 10503, 10501, 10510, 10511, 10512, 10513, 10514, 10515, 10537, 10538, 10540, 10541, 10542, 10543, 10544, 10545, 10546, 10547, 10548, 10549, 10550, 10551, 10552, 10554, 10555, 10556, 10557, 10558, 10560, 10561, 10562, 10601, 10602, 10604, 10605, 10606, 10607, 10608, 10609, 10610, 10611, 10612, 10613, 10614, 10615, 10616, 10617, 10618, 10619, 10620, 10621, 10622, 10623, 10624, 10625, 10626, 10627, 10628, 10629, 10630, 10631, 10632, 10633, 10634, 10635, 10636, 10637, 10638, 10639, 10640, 10641, 10642, 10643, 10644, 10645, 10646, 10647, 10648, 10649, 10650, 10268, 10271, 10278, 10279, 10281, 11015, 11016, 11017, 11021, 11022, 11023, 11024, 11025, 11026, 11027, 11028, 11029, 11030, 11031, 11032, 11033, 11034, 11035, 11036, 11040, 11059, 11065, 9021, 9022, 10209, 9100, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 4035, 11427, 11431, 11432, 11433, 11436, 11437, 11438, 11439, 11440, 11443, 11444, 11445, 11446, 11447, 11448, 11449, 11450, 11451, 11452, 11453, 11454, 11455, 11456, 11457, 11458, 11459, 11460, 11461, 11462, 11463, 11464, 11466, 11467, 11468, 11469, 7174, 11651, 11652, 11653, 11654, 11655, 11657, 11658, 11660, 11661, 11663, 11664, 11666, 11667, 11668, 11669, 11670, 11671, 11672, 11673, 11674, 2016, 2017, 10158, 2018, 10160, 10162, 4001, 4004, 4006, 4008, 4010, 4012, 4013, 4014, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 10061, 10062, 10063, 10064, 10065, 10066, 10067, 10068, 10069, 10070, 10071, 10072, 10073, 10074, 10075, 10076, 10077, 10078, 10079, 10080, 10081, 10082, 10083, 10084, 10085, 10086, 10087, 10088, 10089, 10090, 10091, 10092, 10093, 10094, 2009, 2010, 10153, 10156, 10144, 10145, 4002, 10146, 10147, 10148, 10149, 10150, 10151, 10152, 10154, 10155, 4003, 10157, 4005, 10159, 4007, 10161, 4009, 10163, 4011, 10165, 10166, 10167, 4015, 4016, 10170, 10171, 10172, 10173, 10174, 10175, 10176, 10177, 10178, 10179, 10180, 10181, 10182, 10183, 10164, 10185, 10186, 10187, 10188, 10189, 10190, 2001, 2002, 2003, 10168, 2007, 10200, 2008, 10202, 2011, 10169, 10204, 2014, 2015, 10206, 10205, 10201, 2019, 10207, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2020, 2030, 2031, 2032, 2033, 2034, 2035, 2029, 2037, 2039, 2040, 2041, 2042, 2044, 2045, 2046, 2047}\n"
     ]
    }
   ],
   "source": [
    "# Wie viele Fahrzeuge sind in den Fahrzeiten CSVs enthalten?\n",
    "fahrzeuge = set()\n",
    "\n",
    "for df in fahrzeiten_dfs.values():\n",
    "    fahrzeuge.update(df['fahrzeug'].unique())\n",
    "\n",
    "print(f'Anzahl Fahrzeuge: {len(fahrzeuge)}')\n",
    "print(fahrzeuge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Es gibt 576 Fahrzeuge.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weiteres\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Welcher Kanton hat die meisten Einträge in der Passagierfrequenz CSV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "canton_counts = {}\n",
    "\n",
    "cantons = passagierfrequenz_df['kt_ct_cantone'].unique()\n",
    "for canton in cantons:\n",
    "    canton_counts[canton] = passagierfrequenz_df[passagierfrequenz_df['kt_ct_cantone'] == canton].shape[0]\n",
    "\n",
    "canton_dict = {\n",
    "    'AG': ('Aargau', [47.387666, 8.247164]),\n",
    "    'BE': ('Bern', [46.948020, 7.447433]),\n",
    "    'FR': ('Fribourg', [46.806467, 7.161594]),\n",
    "    'GE': ('Genève', [46.204391, 6.143158]),\n",
    "    'GL': ('Glarus', [47.040182, 9.067609]),\n",
    "    'GR': ('Graubünden', [46.656987, 9.578027]),\n",
    "    'JU': ('Jura', [47.350000, 7.350000]),\n",
    "    'LU': ('Luzern', [47.050000, 8.300000]),\n",
    "    'NE': ('Neuchâtel', [46.991789, 6.930000]),\n",
    "    'SG': ('St. Gallen', [47.423058, 9.377083]),\n",
    "    'SH': ('Schaffhausen', [47.697320, 8.634910]),\n",
    "    'SZ': ('Schwyz', [47.020000, 8.650000]),\n",
    "    'SO': ('Solothurn', [47.206667, 7.537778]),\n",
    "    'TG': ('Thurgau', [47.566667, 9.166667]),\n",
    "    'TI': ('Ticino', [46.331734, 8.800452]),\n",
    "    'UR': ('Uri', [46.900000, 8.633333]),\n",
    "    'VS': ('Valais', [46.191079, 7.737933]),\n",
    "    'VD': ('Vaud', [46.533333, 6.666667]),\n",
    "    'ZG': ('Zug', [47.166667, 8.516667]),\n",
    "    'ZH': ('Zürich', [47.366667, 8.550000]),\n",
    "    'AR': ('Appenzell Ausserrhoden', [47.366667, 9.300000]),\n",
    "    'AI': ('Appenzell Innerrhoden', [47.316667, 9.416667]),\n",
    "    'BS': ('Basel-Stadt', [47.566667, 7.600000]),\n",
    "    'BL': ('Basel-Landschaft', [47.450000, 7.750000]),\n",
    "    'OW': ('Obwalden', [46.900000, 8.250000]),\n",
    "    'NW': ('Nidwalden', [46.950000, 8.383333])\n",
    "}\n",
    "\n",
    "canton_counts = {canton_dict[k][0]: v for k, v in canton_counts.items() if k in canton_dict.keys() and v > 0}\n",
    "\n",
    "canton_counts_df = pd.DataFrame.from_dict(canton_counts, orient='index', columns=['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_canton_counts(save=False):\n",
    "    # Filter rows where jahr_annee_anno is 2022\n",
    "    passagierfrequenz_df_2022 = passagierfrequenz_df.loc[passagierfrequenz_df['jahr_annee_anno'] == 2022]\n",
    "\n",
    "    canton_counts = passagierfrequenz_df_2022['kt_ct_cantone'].value_counts()\n",
    "    canton_counts = canton_counts[canton_counts.index.isin(canton_dict.keys())]\n",
    "\n",
    "    # Replace abbreviations with full names\n",
    "    canton_counts.index = [canton_dict[canton][0] for canton in canton_counts.index]\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(y=canton_counts.index, x=canton_counts, order=canton_counts.index, ax=ax, palette='Set2', zorder=2)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Amount of Stations for every Canton in Passagierfrequenz CSV')\n",
    "    plt.ylabel('')\n",
    "    plt.xlabel('Amount of Entries')\n",
    "    plt.grid(axis='x', zorder=1)\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('../figures/exploration/canton_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_canton_counts(save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_canton_map():\n",
    "    canton_map = folium.Map(location=[46.8, 8.33], zoom_start=8, tiles='cartodbpositron')\n",
    "    folium.Choropleth(\n",
    "        geo_data='../raw_data/switzerland.geojson',\n",
    "        data=canton_counts_df,\n",
    "        columns=[canton_counts_df.index, 'count'],\n",
    "        key_on='feature.properties.NAME',\n",
    "        fill_color='YlGn',\n",
    "        fill_opacity=0.7,\n",
    "        line_opacity=0.2,\n",
    "        legend_name='Amount of entries in passagierfrequenz.csv',\n",
    "        legend_kwds={'loc': 'bottom left'}\n",
    "    ).add_to(canton_map)\n",
    "\n",
    "    # Create a reverse dictionary that maps the full canton names to their abbreviations\n",
    "    reverse_canton_dict = {v[0]: k for k, v in canton_dict.items()}\n",
    "\n",
    "    # # For each canton, add a marker to the map\n",
    "    # for canton, count in canton_counts.items():\n",
    "    #     # Get the abbreviation of the canton\n",
    "    #     canton_abbr = reverse_canton_dict[canton]\n",
    "\n",
    "    #     # Get the coordinates of the canton\n",
    "    #     coords = canton_dict[canton_abbr][1]\n",
    "\n",
    "    #     # Create a Marker and add it to the map\n",
    "    #     folium.Marker(\n",
    "    #         location=coords,\n",
    "    #         popup=f'{canton}\\n{count}',\n",
    "    #         icon=folium.Icon(icon='info-sign')\n",
    "    #     ).add_to(canton_map)\n",
    "\n",
    "    return canton_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_canton_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe Interaktion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "An welchen Wochentagen gibt es die meisten Einträge in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_weekday_counts(save=False):\n",
    "    weekday_counts = {}\n",
    "\n",
    "    for betriebsdatum, count in betriebsdatum_counts.items():\n",
    "        weekday = calendar.day_name[datetime.strptime(betriebsdatum, '%d.%m.%y').weekday()]\n",
    "        if weekday in weekday_counts:\n",
    "            weekday_counts[weekday] += count\n",
    "        else:\n",
    "            weekday_counts[weekday] = count\n",
    "            \n",
    "    df_weekday_counts = pd.DataFrame(weekday_counts.items(), columns=['Weekday', 'Count'])\n",
    "    weekday_to_num = {'Monday': 1, 'Tuesday': 2, 'Wednesday': 3, 'Thursday': 4, 'Friday': 5, 'Saturday': 6, 'Sunday': 7}\n",
    "    df_weekday_counts['Weekday_num'] = df_weekday_counts['Weekday'].map(weekday_to_num)\n",
    "    df_weekday_counts = df_weekday_counts.sort_values('Weekday_num')\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.barplot(x=df_weekday_counts['Weekday'], y=df_weekday_counts['Count'], order=df_weekday_counts['Weekday'], ax=ax, palette='Set2', zorder=2)\n",
    "    ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    plt.title(f'Amount of Entries for every Weekday in Fahrzeiten CSVs ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('Entries')\n",
    "    plt.grid(axis='y', zorder=1)\n",
    "    \n",
    "    if save:\n",
    "        plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/weekday_count.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "create_bar_chart_weekday_counts(save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe weekday_count.png\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frage:\n",
    "Wie viele unterschiedliche Einträge gibt es pro Spalte in den Fahrzeiten CSVs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bar_chart_unique_entries_per_column(df, save=True, df_name='placeholder'):\n",
    "    unique_entries_per_column = {}\n",
    "\n",
    "    for column in df.columns:\n",
    "        unique_entries_per_column[column] = df[column].unique().shape[0]\n",
    "\n",
    "    df_unique_entries_per_column = pd.DataFrame(unique_entries_per_column.items(), columns=['Column', 'Count'])\n",
    "    \n",
    "    # Add a new column that indicates whether each column only contains unique values\n",
    "    total_rows = df.shape[0]\n",
    "    df_unique_entries_per_column['Is Unique'] = df_unique_entries_per_column['Count'] == total_rows\n",
    "    \n",
    "    # Sort the dataframe in ascending order\n",
    "    df_unique_entries_per_column = df_unique_entries_per_column.sort_values('Count')\n",
    "\n",
    "    # Create the bar chart\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    sns.barplot(y=df_unique_entries_per_column['Column'], x=df_unique_entries_per_column['Count'], order=df_unique_entries_per_column['Column'], ax=ax, palette='Set2', zorder=2)\n",
    "    ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x)))\n",
    "    if df_name == 'haltepunkt' or df_name == 'haltestelle':\n",
    "        plt.title(f'Unique Entries per Column in {df_name.title()} ({fahrzeiten_dir.split(\"/\")[-2].split(\"_\")[1]})')\n",
    "    else:\n",
    "        plt.title(f'Unique Entries per Column in {df_name.title()} (Total Rows: {total_rows})')\n",
    "    plt.ylabel('Column')\n",
    "    plt.xlabel('Unique Entries')\n",
    "    plt.grid(axis='x', zorder=1)\n",
    "    \n",
    "    # Add a vertical line at the position of total_rows\n",
    "    plt.axvline(x=total_rows, color='red', linestyle='--', linewidth=1)\n",
    "        \n",
    "    if save:\n",
    "        if df_name == 'haltepunkt' or df_name == 'haltestelle':\n",
    "            plt.savefig(f'../figures/exploration/{fahrzeiten_dir.split(\"/\")[-2]}/unique_entries_per_column_{df_name}.png', bbox_inches='tight')\n",
    "        else:\n",
    "            plt.savefig(f'../figures/exploration/unique_entries_per_column_{df_name}.png', bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n",
      "c:\\Users\\tklas\\anaconda3\\envs\\new_base\\Lib\\site-packages\\seaborn\\_oldcore.py:1498: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(vector):\n"
     ]
    }
   ],
   "source": [
    "# create_bar_chart_unique_entries_per_column(passagierfrequenz_df, save=True, df_name='passagierfrequenz')\n",
    "create_bar_chart_unique_entries_per_column(haltepunkt_df, save=True, df_name='haltepunkt')\n",
    "create_bar_chart_unique_entries_per_column(haltestelle_df, save=True, df_name='haltestelle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Antwort:\n",
    "Siehe unique_entries_per_column_[...].png\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
